{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Type your message</span>: </pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mType your message\u001b[0m: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Enter image paths separated by comma (if any)</span>: </pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mEnter image paths separated by comma (if any)\u001b[0m: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">User:</span> <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">user-query</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;hi can you please specify which model you are and your latest training date&lt;</span><span style=\"color: #800080; text-decoration-color: #800080\">/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">user-query</span><span style=\"font-weight: bold\">&gt;</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mUser:\u001b[0m \u001b[1m<\u001b[0m\u001b[1;95muser-query\u001b[0m\u001b[39m>hi can you please specify which model you are and your latest training date<\u001b[0m\u001b[35m/\u001b[0m\u001b[95muser-query\u001b[0m\u001b[1m>\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Assistant:</span> <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">assistant-response</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'id'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-9uKeoqHfvvyFwB7Z7DPjin1JaGjon'</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'object'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'chat.completion'</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'created'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1723212802</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'model'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini-2024-07-18'</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'choices'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[{</span><span style=\"color: #008000; text-decoration-color: #008000\">'index'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'message'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'content'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">\"I am ChatGPT, based on OpenAI's GPT-3.5 model, and my training data goes up to October 2021. If you </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">have any questions or need assistance, feel free to ask!\"</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'refusal'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">}</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'logprobs'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'finish_reason'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">}]</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'usage'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'prompt_tokens'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">34</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">43</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'total_tokens'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">77</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">}</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'system_fingerprint'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'fp_48196bc67a'</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">}</span><span style=\"color: #000000; text-decoration-color: #000000\">&lt;</span><span style=\"color: #800080; text-decoration-color: #800080\">/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">assistant-response</span><span style=\"font-weight: bold\">&gt;</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mAssistant:\u001b[0m \u001b[1m<\u001b[0m\u001b[1;95massistant-response\u001b[0m\u001b[39m>\u001b[0m\u001b[1;39m{\u001b[0m\u001b[32m'id'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'chatcmpl-9uKeoqHfvvyFwB7Z7DPjin1JaGjon'\u001b[0m\u001b[39m, \u001b[0m\u001b[32m'object'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'chat.completion'\u001b[0m\u001b[39m, \u001b[0m\n",
       "\u001b[32m'created'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m1723212802\u001b[0m\u001b[39m, \u001b[0m\u001b[32m'model'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'gpt-4o-mini-2024-07-18'\u001b[0m\u001b[39m, \u001b[0m\u001b[32m'choices'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;39m[\u001b[0m\u001b[1;39m{\u001b[0m\u001b[32m'index'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[39m, \u001b[0m\u001b[32m'message'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;39m{\u001b[0m\u001b[32m'role'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'assistant'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[32m'content'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m\"I am ChatGPT, based on OpenAI's GPT-3.5 model, and my training data goes up to October 2021. If you \u001b[0m\n",
       "\u001b[32mhave any questions or need assistance, feel free to ask!\"\u001b[0m\u001b[39m, \u001b[0m\u001b[32m'refusal'\u001b[0m\u001b[39m: \u001b[0m\u001b[3;35mNone\u001b[0m\u001b[1;39m}\u001b[0m\u001b[39m, \u001b[0m\u001b[32m'logprobs'\u001b[0m\u001b[39m: \u001b[0m\u001b[3;35mNone\u001b[0m\u001b[39m, \u001b[0m\u001b[32m'finish_reason'\u001b[0m\u001b[39m: \u001b[0m\n",
       "\u001b[32m'stop'\u001b[0m\u001b[1;39m}\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m, \u001b[0m\u001b[32m'usage'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;39m{\u001b[0m\u001b[32m'prompt_tokens'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m34\u001b[0m\u001b[39m, \u001b[0m\u001b[32m'completion_tokens'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m43\u001b[0m\u001b[39m, \u001b[0m\u001b[32m'total_tokens'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m77\u001b[0m\u001b[1;39m}\u001b[0m\u001b[39m, \u001b[0m\u001b[32m'system_fingerprint'\u001b[0m\u001b[39m: \u001b[0m\n",
       "\u001b[32m'fp_48196bc67a'\u001b[0m\u001b[1;39m}\u001b[0m\u001b[39m<\u001b[0m\u001b[35m/\u001b[0m\u001b[95massistant-response\u001b[0m\u001b[1m>\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Do you want to continue? (yes/no)</span>: </pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mDo you want to continue? (yes/no)\u001b[0m: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import base64\n",
    "import openai\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "from rich.console import Console\n",
    "from rich.prompt import Prompt\n",
    "from rich import box\n",
    "from rich.table import Table\n",
    "\n",
    "# Initialize console for rich output\n",
    "console = Console()\n",
    "\n",
    "# Load the OpenAI API key\n",
    "api_key = \"\"  # Clear API key\n",
    "\n",
    "# Construct the initial system message\n",
    "initial_system_message = \"\"\"\n",
    "\"\"\"\n",
    "\n",
    "# Helper function to read image bytes and encode them in base64\n",
    "def read_image_base64(image_path):\n",
    "    if os.path.exists(image_path):\n",
    "        with open(image_path, 'rb') as image_file:\n",
    "            return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    else:\n",
    "        console.print(f\"[bold red]File not found: {image_path}[/bold red]\")\n",
    "        return None\n",
    "\n",
    "# Function to send a prompt (text and/or image) to OpenAI API\n",
    "def process_prompt_openai(system_prompt, chat_history, image_paths=None):\n",
    "    base64_images = [read_image_base64(image_path) for image_path in image_paths] if image_paths else []\n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "    for entry in chat_history:\n",
    "        messages.append({\"role\": entry[\"role\"], \"content\": entry[\"content\"]})\n",
    "    if base64_images:\n",
    "        image_contents = []\n",
    "        for base64_image in base64_images:\n",
    "            image_contents.append({\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                    \"detail\": \"high\"\n",
    "                }\n",
    "            })\n",
    "        messages.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": image_contents\n",
    "        })\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"gpt-4o-mini\",\n",
    "        \"messages\": messages,\n",
    "        \"max_tokens\": 300\n",
    "    }\n",
    "\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "    return response.json()\n",
    "\n",
    "# Function to handle message sending and processing\n",
    "def send_message():\n",
    "    local_chat_history = []\n",
    "    user_prompt = Prompt.ask(\"[bold cyan]Type your message[/bold cyan]\")\n",
    "    image_paths = Prompt.ask(\"[bold cyan]Enter image paths separated by comma (if any)[/bold cyan]\").split(\",\")\n",
    "\n",
    "    imgpaths = [path.strip() for path in image_paths if path.strip()] if image_paths else []\n",
    "\n",
    "    if not user_prompt and not imgpaths:\n",
    "        console.print(\"[bold yellow]Please provide a text input, an image, or both.[/bold yellow]\")\n",
    "    else:\n",
    "        if imgpaths:\n",
    "            for imgpath in imgpaths:\n",
    "                local_chat_history.append({\"role\": \"user\", \"content\": f\"<image-upload>{imgpath}</image-upload>\"})\n",
    "\n",
    "        if user_prompt:\n",
    "            local_chat_history.append({\"role\": \"user\", \"content\": f\"<user-query>{user_prompt}</user-query>\"})\n",
    "\n",
    "        # Call the OpenAI API with the chat history\n",
    "        response = process_prompt_openai(initial_system_message, local_chat_history, imgpaths)\n",
    "        local_chat_history.append({\"role\": \"assistant\", \"content\": f\"<assistant-response>{response}</assistant-response>\"})\n",
    "\n",
    "        # Display the chat history\n",
    "        for message in local_chat_history:\n",
    "            if message[\"role\"] == \"user\":\n",
    "                console.print(f\"[bold blue]User:[/bold blue] {message['content']}\")\n",
    "            elif message[\"role\"] == \"assistant\":\n",
    "                console.print(f\"[bold green]Assistant:[/bold green] {message['content']}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    while True:\n",
    "        send_message()\n",
    "        continue_chat = Prompt.ask(\"[bold cyan]Do you want to continue? (yes/no)[/bold cyan]\").lower()\n",
    "        if continue_chat != 'yes':\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Type your message (#1)</span>: </pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mType your message (#1)\u001b[0m: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Enter image paths separated by comma (if any, #1)</span>: </pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mEnter image paths separated by comma (if any, #1)\u001b[0m: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                                  Chat History #1                                                  </span>\n",
       "╭───────────┬─────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│<span style=\"font-weight: bold\"> Role      </span>│<span style=\"font-weight: bold\"> Message                                                                                             </span>│\n",
       "├───────────┼─────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> User      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> &lt;user-query&gt;hi&lt;/user-query&gt;                                                                         </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Assistant </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> &lt;assistant-response&gt;{'id': 'chatcmpl-9uKmdbi9y4XW6QwjR1Pcfc4BHfyk3', 'object': 'chat.completion',   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 'created': 1723213287, 'model': 'gpt-4o-mini-2024-07-18', 'choices': [{'index': 0, 'message':       </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> {'role': 'assistant', 'content': 'Hello! How can I assist you today?', 'refusal': None},            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 21, 'completion_tokens': 9, </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 'total_tokens': 30}, 'system_fingerprint': 'fp_507c9469a1'}&lt;/assistant-response&gt;                    </span>│\n",
       "╰───────────┴─────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                                  Chat History #1                                                  \u001b[0m\n",
       "╭───────────┬─────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│\u001b[1m \u001b[0m\u001b[1mRole     \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1mMessage                                                                                            \u001b[0m\u001b[1m \u001b[0m│\n",
       "├───────────┼─────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│\u001b[36m \u001b[0m\u001b[36mUser     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m<user-query>hi</user-query>                                                                        \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mAssistant\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m<assistant-response>{'id': 'chatcmpl-9uKmdbi9y4XW6QwjR1Pcfc4BHfyk3', 'object': 'chat.completion',  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m           \u001b[0m│\u001b[35m \u001b[0m\u001b[35m'created': 1723213287, 'model': 'gpt-4o-mini-2024-07-18', 'choices': [{'index': 0, 'message':      \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m           \u001b[0m│\u001b[35m \u001b[0m\u001b[35m{'role': 'assistant', 'content': 'Hello! How can I assist you today?', 'refusal': None},           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m           \u001b[0m│\u001b[35m \u001b[0m\u001b[35m'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 21, 'completion_tokens': 9,\u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m           \u001b[0m│\u001b[35m \u001b[0m\u001b[35m'total_tokens': 30}, 'system_fingerprint': 'fp_507c9469a1'}</assistant-response>                   \u001b[0m\u001b[35m \u001b[0m│\n",
       "╰───────────┴─────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Do you want to continue? (yes/no)</span>: </pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mDo you want to continue? (yes/no)\u001b[0m: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Type your message (#2)</span>: </pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mType your message (#2)\u001b[0m: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Enter image paths separated by comma (if any, #2)</span>: </pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mEnter image paths separated by comma (if any, #2)\u001b[0m: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                                  Chat History #2                                                  </span>\n",
       "╭───────────┬─────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│<span style=\"font-weight: bold\"> Role      </span>│<span style=\"font-weight: bold\"> Message                                                                                             </span>│\n",
       "├───────────┼─────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> User      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> &lt;user-query&gt;hi&lt;/user-query&gt;                                                                         </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Assistant </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> &lt;assistant-response&gt;{'id': 'chatcmpl-9uKmdbi9y4XW6QwjR1Pcfc4BHfyk3', 'object': 'chat.completion',   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 'created': 1723213287, 'model': 'gpt-4o-mini-2024-07-18', 'choices': [{'index': 0, 'message':       </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> {'role': 'assistant', 'content': 'Hello! How can I assist you today?', 'refusal': None},            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 21, 'completion_tokens': 9, </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 'total_tokens': 30}, 'system_fingerprint': 'fp_507c9469a1'}&lt;/assistant-response&gt;                    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> User      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> &lt;user-query&gt;could you tell me the population of bnagalore&lt;/user-query&gt;                              </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Assistant </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> &lt;assistant-response&gt;{'id': 'chatcmpl-9uKnAOjz2emOzuND1SVn7Mrdo1s6h', 'object': 'chat.completion',   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 'created': 1723213320, 'model': 'gpt-4o-mini-2024-07-18', 'choices': [{'index': 0, 'message':       </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> {'role': 'assistant', 'content': 'As of my last update, the population of Bangalore (Bengaluru),    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> India, was estimated to be around 12 million in the metropolitan area. However, population figures  </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> can change over time due to growth and new census data. For the most accurate and current           </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> population statistics, I recommend checking the latest data from official sources like the Census   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> of India or local government reports.', 'refusal': None}, 'logprobs': None, 'finish_reason':        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 'stop'}], 'usage': {'prompt_tokens': 212, 'completion_tokens': 75, 'total_tokens': 287},            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 'system_fingerprint': 'fp_48196bc67a'}&lt;/assistant-response&gt;                                         </span>│\n",
       "╰───────────┴─────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                                  Chat History #2                                                  \u001b[0m\n",
       "╭───────────┬─────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│\u001b[1m \u001b[0m\u001b[1mRole     \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1mMessage                                                                                            \u001b[0m\u001b[1m \u001b[0m│\n",
       "├───────────┼─────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│\u001b[36m \u001b[0m\u001b[36mUser     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m<user-query>hi</user-query>                                                                        \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mAssistant\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m<assistant-response>{'id': 'chatcmpl-9uKmdbi9y4XW6QwjR1Pcfc4BHfyk3', 'object': 'chat.completion',  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m           \u001b[0m│\u001b[35m \u001b[0m\u001b[35m'created': 1723213287, 'model': 'gpt-4o-mini-2024-07-18', 'choices': [{'index': 0, 'message':      \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m           \u001b[0m│\u001b[35m \u001b[0m\u001b[35m{'role': 'assistant', 'content': 'Hello! How can I assist you today?', 'refusal': None},           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m           \u001b[0m│\u001b[35m \u001b[0m\u001b[35m'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 21, 'completion_tokens': 9,\u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m           \u001b[0m│\u001b[35m \u001b[0m\u001b[35m'total_tokens': 30}, 'system_fingerprint': 'fp_507c9469a1'}</assistant-response>                   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mUser     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m<user-query>could you tell me the population of bnagalore</user-query>                             \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mAssistant\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m<assistant-response>{'id': 'chatcmpl-9uKnAOjz2emOzuND1SVn7Mrdo1s6h', 'object': 'chat.completion',  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m           \u001b[0m│\u001b[35m \u001b[0m\u001b[35m'created': 1723213320, 'model': 'gpt-4o-mini-2024-07-18', 'choices': [{'index': 0, 'message':      \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m           \u001b[0m│\u001b[35m \u001b[0m\u001b[35m{'role': 'assistant', 'content': 'As of my last update, the population of Bangalore (Bengaluru),   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m           \u001b[0m│\u001b[35m \u001b[0m\u001b[35mIndia, was estimated to be around 12 million in the metropolitan area. However, population figures \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m           \u001b[0m│\u001b[35m \u001b[0m\u001b[35mcan change over time due to growth and new census data. For the most accurate and current          \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m           \u001b[0m│\u001b[35m \u001b[0m\u001b[35mpopulation statistics, I recommend checking the latest data from official sources like the Census  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m           \u001b[0m│\u001b[35m \u001b[0m\u001b[35mof India or local government reports.', 'refusal': None}, 'logprobs': None, 'finish_reason':       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m           \u001b[0m│\u001b[35m \u001b[0m\u001b[35m'stop'}], 'usage': {'prompt_tokens': 212, 'completion_tokens': 75, 'total_tokens': 287},           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m           \u001b[0m│\u001b[35m \u001b[0m\u001b[35m'system_fingerprint': 'fp_48196bc67a'}</assistant-response>                                        \u001b[0m\u001b[35m \u001b[0m│\n",
       "╰───────────┴─────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Do you want to continue? (yes/no)</span>: </pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mDo you want to continue? (yes/no)\u001b[0m: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Do you want to continue? (yes/no)</span>: </pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mDo you want to continue? (yes/no)\u001b[0m: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import base64\n",
    "import openai\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "from rich.console import Console\n",
    "from rich.prompt import Prompt\n",
    "from rich import box\n",
    "from rich.table import Table\n",
    "\n",
    "# Initialize console for rich output\n",
    "console = Console()\n",
    "\n",
    "# Load the OpenAI API key\n",
    "api_key = \"\"  # Clear API key\n",
    "\n",
    "# Construct the initial system message\n",
    "initial_system_message = \"\"\"\n",
    "\"\"\"\n",
    "\n",
    "# Helper function to read image bytes and encode them in base64\n",
    "def read_image_base64(image_path):\n",
    "    if os.path.exists(image_path):\n",
    "        with open(image_path, 'rb') as image_file:\n",
    "            return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    else:\n",
    "        console.print(f\"[bold red]File not found: {image_path}[/bold red]\")\n",
    "        return None\n",
    "\n",
    "# Function to send a prompt (text and/or image) to OpenAI API\n",
    "def process_prompt_openai(system_prompt, chat_history, image_paths=None):\n",
    "    base64_images = [read_image_base64(image_path) for image_path in image_paths] if image_paths else []\n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "    for entry in chat_history:\n",
    "        messages.append({\"role\": entry[\"role\"], \"content\": entry[\"content\"]})\n",
    "    if base64_images:\n",
    "        image_contents = []\n",
    "        for base64_image in base64_images:\n",
    "            image_contents.append({\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                    \"detail\": \"high\"\n",
    "                }\n",
    "            })\n",
    "        messages.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": image_contents\n",
    "        })\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"gpt-4o-mini\",\n",
    "        \"messages\": messages,\n",
    "        \"max_tokens\": 300\n",
    "    }\n",
    "\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "    return response.json()\n",
    "\n",
    "def send_message():\n",
    "    local_chat_history = []\n",
    "    counter = 1  # Initialize a message counter\n",
    "    while True:\n",
    "        user_prompt = Prompt.ask(f\"[bold cyan]Type your message (#{counter})[/bold cyan]\")\n",
    "        image_paths = Prompt.ask(f\"[bold cyan]Enter image paths separated by comma (if any, #{counter})[/bold cyan]\").split(\",\")\n",
    "\n",
    "        imgpaths = [path.strip() for path in image_paths if path.strip()] if image_paths else []\n",
    "\n",
    "        if not user_prompt and not imgpaths:\n",
    "            console.print(\"[bold yellow]Please provide a text input, an image, or both.[/bold yellow]\")\n",
    "        else:\n",
    "            if imgpaths:\n",
    "                for imgpath in imgpaths:\n",
    "                    local_chat_history.append({\"role\": \"user\", \"content\": f\"\"\"<image-upload>{imgpath}</image-upload>\"\"\"})\n",
    "\n",
    "            if user_prompt:\n",
    "                local_chat_history.append({\"role\": \"user\", \"content\": f\"\"\"<user-query>{user_prompt}</user-query>\"\"\"})\n",
    "\n",
    "            # Call the OpenAI API with the chat history\n",
    "            response = process_prompt_openai(initial_system_message, local_chat_history, imgpaths)\n",
    "            assistant_response = response  # No need to call .json() again since it's already a dict\n",
    "            local_chat_history.append({\"role\": \"assistant\", \"content\": f\"\"\"<assistant-response>{assistant_response}</assistant-response>\"\"\"})\n",
    "\n",
    "            # Create a table to display the chat history\n",
    "            table = Table(title=f\"Chat History #{counter}\", box=box.ROUNDED)\n",
    "            table.add_column(\"Role\", style=\"cyan\", no_wrap=True)\n",
    "            table.add_column(\"Message\", style=\"magenta\")\n",
    "\n",
    "            for message in local_chat_history:\n",
    "                if message[\"role\"] == \"user\":\n",
    "                    table.add_row(\"User\", message[\"content\"])\n",
    "                elif message[\"role\"] == \"assistant\":\n",
    "                    table.add_row(\"Assistant\", message[\"content\"])\n",
    "\n",
    "            # Display the chat history in a table\n",
    "            console.print(table)\n",
    "            counter += 1  # Increment the message counter\n",
    "\n",
    "        continue_chat = Prompt.ask(\"[bold cyan]Do you want to continue? (yes/no)[/bold cyan]\").lower()\n",
    "        if continue_chat != 'yes':\n",
    "            break\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    while True:\n",
    "        send_message()\n",
    "        continue_chat = Prompt.ask(\"[bold cyan]Do you want to continue? (yes/no)[/bold cyan]\").lower()\n",
    "        if continue_chat != 'yes':\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Type your message (#1)</span>: </pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mType your message (#1)\u001b[0m: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Enter image paths separated by comma (if any, #1)</span>: </pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mEnter image paths separated by comma (if any, #1)\u001b[0m: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                    Chat History #1                                    </span>╭───── <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Response Stats</span> ─────╮\n",
       "╭───────────┬─────────────────────────────────────────────────────────────────────────╮│          Model:          │\n",
       "│<span style=\"font-weight: bold\"> Role      </span>│<span style=\"font-weight: bold\"> Message                                                                 </span>││  gpt-4o-mini-2024-07-18  │\n",
       "├───────────┼─────────────────────────────────────────────────────────────────────────┤│     Total Tokens: 30     │\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> User      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> &lt;user-query&gt;hi&lt;/user-query&gt;                                             </span>││    Prompt Tokens: 21     │\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Assistant </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> &lt;assistant-response&gt;{'id': 'chatcmpl-9uKu9w0F4GeZnegIjlxl7XRRuVZq0',    </span>││   Completion Tokens: 9   │\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 'object': 'chat.completion', 'created': 1723213753, 'model':            </span>││   System Fingerprint:    │\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 'gpt-4o-mini-2024-07-18', 'choices': [{'index': 0, 'message': {'role':  </span>││      fp_48196bc67a       │\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 'assistant', 'content': 'Hello! How can I assist you today?',           </span>│╰──────────────────────────╯\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 'refusal': None}, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': </span>│                            \n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> {'prompt_tokens': 21, 'completion_tokens': 9, 'total_tokens': 30},      </span>│                            \n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 'system_fingerprint': 'fp_48196bc67a'}&lt;/assistant-response&gt;             </span>│                            \n",
       "╰───────────┴─────────────────────────────────────────────────────────────────────────╯                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                    Chat History #1                                    \u001b[0m╭───── \u001b[1;32mResponse Stats\u001b[0m ─────╮\n",
       "╭───────────┬─────────────────────────────────────────────────────────────────────────╮│          Model:          │\n",
       "│\u001b[1m \u001b[0m\u001b[1mRole     \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1mMessage                                                                \u001b[0m\u001b[1m \u001b[0m││  gpt-4o-mini-2024-07-18  │\n",
       "├───────────┼─────────────────────────────────────────────────────────────────────────┤│     Total Tokens: 30     │\n",
       "│\u001b[36m \u001b[0m\u001b[36mUser     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m<user-query>hi</user-query>                                            \u001b[0m\u001b[35m \u001b[0m││    Prompt Tokens: 21     │\n",
       "│\u001b[36m \u001b[0m\u001b[36mAssistant\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m<assistant-response>{'id': 'chatcmpl-9uKu9w0F4GeZnegIjlxl7XRRuVZq0',   \u001b[0m\u001b[35m \u001b[0m││   Completion Tokens: 9   │\n",
       "│\u001b[36m           \u001b[0m│\u001b[35m \u001b[0m\u001b[35m'object': 'chat.completion', 'created': 1723213753, 'model':           \u001b[0m\u001b[35m \u001b[0m││   System Fingerprint:    │\n",
       "│\u001b[36m           \u001b[0m│\u001b[35m \u001b[0m\u001b[35m'gpt-4o-mini-2024-07-18', 'choices': [{'index': 0, 'message': {'role': \u001b[0m\u001b[35m \u001b[0m││      fp_48196bc67a       │\n",
       "│\u001b[36m           \u001b[0m│\u001b[35m \u001b[0m\u001b[35m'assistant', 'content': 'Hello! How can I assist you today?',          \u001b[0m\u001b[35m \u001b[0m│╰──────────────────────────╯\n",
       "│\u001b[36m           \u001b[0m│\u001b[35m \u001b[0m\u001b[35m'refusal': None}, 'logprobs': None, 'finish_reason': 'stop'}], 'usage':\u001b[0m\u001b[35m \u001b[0m│                            \n",
       "│\u001b[36m           \u001b[0m│\u001b[35m \u001b[0m\u001b[35m{'prompt_tokens': 21, 'completion_tokens': 9, 'total_tokens': 30},     \u001b[0m\u001b[35m \u001b[0m│                            \n",
       "│\u001b[36m           \u001b[0m│\u001b[35m \u001b[0m\u001b[35m'system_fingerprint': 'fp_48196bc67a'}</assistant-response>            \u001b[0m\u001b[35m \u001b[0m│                            \n",
       "╰───────────┴─────────────────────────────────────────────────────────────────────────╯                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Do you want to continue? (yes/no)</span>: </pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mDo you want to continue? (yes/no)\u001b[0m: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Type your message (#2)</span>: </pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mType your message (#2)\u001b[0m: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Enter image paths separated by comma (if any, #2)</span>: </pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mEnter image paths separated by comma (if any, #2)\u001b[0m: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                    Chat History #2                                    </span>╭───── <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Response Stats</span> ─────╮\n",
       "╭───────────┬─────────────────────────────────────────────────────────────────────────╮│          Model:          │\n",
       "│<span style=\"font-weight: bold\"> Role      </span>│<span style=\"font-weight: bold\"> Message                                                                 </span>││  gpt-4o-mini-2024-07-18  │\n",
       "├───────────┼─────────────────────────────────────────────────────────────────────────┤│    Total Tokens: 253     │\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> User      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> &lt;user-query&gt;hi&lt;/user-query&gt;                                             </span>││    Prompt Tokens: 213    │\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Assistant </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> &lt;assistant-response&gt;{'id': 'chatcmpl-9uKu9w0F4GeZnegIjlxl7XRRuVZq0',    </span>││  Completion Tokens: 40   │\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 'object': 'chat.completion', 'created': 1723213753, 'model':            </span>││   System Fingerprint:    │\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 'gpt-4o-mini-2024-07-18', 'choices': [{'index': 0, 'message': {'role':  </span>││      fp_48196bc67a       │\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 'assistant', 'content': 'Hello! How can I assist you today?',           </span>│╰──────────────────────────╯\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 'refusal': None}, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': </span>│                            \n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> {'prompt_tokens': 21, 'completion_tokens': 9, 'total_tokens': 30},      </span>│                            \n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 'system_fingerprint': 'fp_48196bc67a'}&lt;/assistant-response&gt;             </span>│                            \n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> User      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> &lt;user-query&gt;whats your name who made you and whats your purpose         </span>│                            \n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> ?&lt;/user-query&gt;                                                          </span>│                            \n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Assistant </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> &lt;assistant-response&gt;{'id': 'chatcmpl-9uKubliwyaYwbOh4KYIlAk5dD4sca',    </span>│                            \n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 'object': 'chat.completion', 'created': 1723213781, 'model':            </span>│                            \n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 'gpt-4o-mini-2024-07-18', 'choices': [{'index': 0, 'message': {'role':  </span>│                            \n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 'assistant', 'content': \"I'm called ChatGPT, and I was created by       </span>│                            \n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> OpenAI. My purpose is to assist, provide information, and engage in     </span>│                            \n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> conversations on a wide range of topics. How can I help you today?\",    </span>│                            \n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 'refusal': None}, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': </span>│                            \n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> {'prompt_tokens': 213, 'completion_tokens': 40, 'total_tokens': 253},   </span>│                            \n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 'system_fingerprint': 'fp_48196bc67a'}&lt;/assistant-response&gt;             </span>│                            \n",
       "╰───────────┴─────────────────────────────────────────────────────────────────────────╯                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                    Chat History #2                                    \u001b[0m╭───── \u001b[1;32mResponse Stats\u001b[0m ─────╮\n",
       "╭───────────┬─────────────────────────────────────────────────────────────────────────╮│          Model:          │\n",
       "│\u001b[1m \u001b[0m\u001b[1mRole     \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1mMessage                                                                \u001b[0m\u001b[1m \u001b[0m││  gpt-4o-mini-2024-07-18  │\n",
       "├───────────┼─────────────────────────────────────────────────────────────────────────┤│    Total Tokens: 253     │\n",
       "│\u001b[36m \u001b[0m\u001b[36mUser     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m<user-query>hi</user-query>                                            \u001b[0m\u001b[35m \u001b[0m││    Prompt Tokens: 213    │\n",
       "│\u001b[36m \u001b[0m\u001b[36mAssistant\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m<assistant-response>{'id': 'chatcmpl-9uKu9w0F4GeZnegIjlxl7XRRuVZq0',   \u001b[0m\u001b[35m \u001b[0m││  Completion Tokens: 40   │\n",
       "│\u001b[36m           \u001b[0m│\u001b[35m \u001b[0m\u001b[35m'object': 'chat.completion', 'created': 1723213753, 'model':           \u001b[0m\u001b[35m \u001b[0m││   System Fingerprint:    │\n",
       "│\u001b[36m           \u001b[0m│\u001b[35m \u001b[0m\u001b[35m'gpt-4o-mini-2024-07-18', 'choices': [{'index': 0, 'message': {'role': \u001b[0m\u001b[35m \u001b[0m││      fp_48196bc67a       │\n",
       "│\u001b[36m           \u001b[0m│\u001b[35m \u001b[0m\u001b[35m'assistant', 'content': 'Hello! How can I assist you today?',          \u001b[0m\u001b[35m \u001b[0m│╰──────────────────────────╯\n",
       "│\u001b[36m           \u001b[0m│\u001b[35m \u001b[0m\u001b[35m'refusal': None}, 'logprobs': None, 'finish_reason': 'stop'}], 'usage':\u001b[0m\u001b[35m \u001b[0m│                            \n",
       "│\u001b[36m           \u001b[0m│\u001b[35m \u001b[0m\u001b[35m{'prompt_tokens': 21, 'completion_tokens': 9, 'total_tokens': 30},     \u001b[0m\u001b[35m \u001b[0m│                            \n",
       "│\u001b[36m           \u001b[0m│\u001b[35m \u001b[0m\u001b[35m'system_fingerprint': 'fp_48196bc67a'}</assistant-response>            \u001b[0m\u001b[35m \u001b[0m│                            \n",
       "│\u001b[36m \u001b[0m\u001b[36mUser     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m<user-query>whats your name who made you and whats your purpose        \u001b[0m\u001b[35m \u001b[0m│                            \n",
       "│\u001b[36m           \u001b[0m│\u001b[35m \u001b[0m\u001b[35m?</user-query>                                                         \u001b[0m\u001b[35m \u001b[0m│                            \n",
       "│\u001b[36m \u001b[0m\u001b[36mAssistant\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m<assistant-response>{'id': 'chatcmpl-9uKubliwyaYwbOh4KYIlAk5dD4sca',   \u001b[0m\u001b[35m \u001b[0m│                            \n",
       "│\u001b[36m           \u001b[0m│\u001b[35m \u001b[0m\u001b[35m'object': 'chat.completion', 'created': 1723213781, 'model':           \u001b[0m\u001b[35m \u001b[0m│                            \n",
       "│\u001b[36m           \u001b[0m│\u001b[35m \u001b[0m\u001b[35m'gpt-4o-mini-2024-07-18', 'choices': [{'index': 0, 'message': {'role': \u001b[0m\u001b[35m \u001b[0m│                            \n",
       "│\u001b[36m           \u001b[0m│\u001b[35m \u001b[0m\u001b[35m'assistant', 'content': \"I'm called ChatGPT, and I was created by      \u001b[0m\u001b[35m \u001b[0m│                            \n",
       "│\u001b[36m           \u001b[0m│\u001b[35m \u001b[0m\u001b[35mOpenAI. My purpose is to assist, provide information, and engage in    \u001b[0m\u001b[35m \u001b[0m│                            \n",
       "│\u001b[36m           \u001b[0m│\u001b[35m \u001b[0m\u001b[35mconversations on a wide range of topics. How can I help you today?\",   \u001b[0m\u001b[35m \u001b[0m│                            \n",
       "│\u001b[36m           \u001b[0m│\u001b[35m \u001b[0m\u001b[35m'refusal': None}, 'logprobs': None, 'finish_reason': 'stop'}], 'usage':\u001b[0m\u001b[35m \u001b[0m│                            \n",
       "│\u001b[36m           \u001b[0m│\u001b[35m \u001b[0m\u001b[35m{'prompt_tokens': 213, 'completion_tokens': 40, 'total_tokens': 253},  \u001b[0m\u001b[35m \u001b[0m│                            \n",
       "│\u001b[36m           \u001b[0m│\u001b[35m \u001b[0m\u001b[35m'system_fingerprint': 'fp_48196bc67a'}</assistant-response>            \u001b[0m\u001b[35m \u001b[0m│                            \n",
       "╰───────────┴─────────────────────────────────────────────────────────────────────────╯                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Do you want to continue? (yes/no)</span>: </pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mDo you want to continue? (yes/no)\u001b[0m: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import base64\n",
    "import openai\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "from rich.console import Console\n",
    "from rich.prompt import Prompt\n",
    "from rich import box\n",
    "from rich.table import Table\n",
    "from rich.align import Align\n",
    "from rich.panel import Panel\n",
    "\n",
    "# Initialize console for rich output\n",
    "console = Console()\n",
    "\n",
    "# Load the OpenAI API key\n",
    "api_key = \"\"  # Clear API key\n",
    "\n",
    "# Construct the initial system message\n",
    "initial_system_message = \"\"\"\n",
    "\"\"\"\n",
    "\n",
    "# Helper function to read image bytes and encode them in base64\n",
    "def read_image_base64(image_path):\n",
    "    if os.path.exists(image_path):\n",
    "        with open(image_path, 'rb') as image_file:\n",
    "            return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    else:\n",
    "        console.print(f\"[bold red]File not found: {image_path}[/bold red]\")\n",
    "        return None\n",
    "\n",
    "# Function to send a prompt (text and/or image) to OpenAI API\n",
    "def process_prompt_openai(system_prompt, chat_history, image_paths=None):\n",
    "    base64_images = [read_image_base64(image_path) for image_path in image_paths] if image_paths else []\n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "    for entry in chat_history:\n",
    "        messages.append({\"role\": entry[\"role\"], \"content\": entry[\"content\"]})\n",
    "    if base64_images:\n",
    "        image_contents = []\n",
    "        for base64_image in base64_images:\n",
    "            image_contents.append({\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                    \"detail\": \"high\"\n",
    "                }\n",
    "            })\n",
    "        messages.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": image_contents\n",
    "        })\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"gpt-4o-mini\",\n",
    "        \"messages\": messages,\n",
    "        \"max_tokens\": 300\n",
    "    }\n",
    "\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "    return response.json()\n",
    "\n",
    "# Function to handle message sending and processing\n",
    "def send_message(local_chat_history, counter):\n",
    "    user_prompt = Prompt.ask(f\"[bold cyan]Type your message (#{counter})[/bold cyan]\")\n",
    "    image_paths = Prompt.ask(f\"[bold cyan]Enter image paths separated by comma (if any, #{counter})[/bold cyan]\").split(\",\")\n",
    "\n",
    "    imgpaths = [path.strip() for path in image_paths if path.strip()] if image_paths else []\n",
    "\n",
    "    if not user_prompt and not imgpaths:\n",
    "        console.print(\"[bold yellow]Please provide a text input, an image, or both.[/bold yellow]\")\n",
    "    else:\n",
    "        if imgpaths:\n",
    "            for imgpath in imgpaths:\n",
    "                local_chat_history.append({\"role\": \"user\", \"content\": f\"\"\"<image-upload>{imgpath}</image-upload>\"\"\"})\n",
    "\n",
    "        if user_prompt:\n",
    "            local_chat_history.append({\"role\": \"user\", \"content\": f\"\"\"<user-query>{user_prompt}</user-query>\"\"\"})\n",
    "\n",
    "        # Call the OpenAI API with the chat history\n",
    "        response = process_prompt_openai(initial_system_message, local_chat_history, imgpaths)\n",
    "        assistant_response = response  # No need to call .json() again since it's already a dict\n",
    "        local_chat_history.append({\"role\": \"assistant\", \"content\": f\"\"\"<assistant-response>{assistant_response}</assistant-response>\"\"\"})\n",
    "\n",
    "        # Extract statistics from the response\n",
    "        stats = {\n",
    "            \"Model\": response['model'],\n",
    "            \"Total Tokens\": response['usage']['total_tokens'],\n",
    "            \"Prompt Tokens\": response['usage']['prompt_tokens'],\n",
    "            \"Completion Tokens\": response['usage']['completion_tokens'],\n",
    "            \"System Fingerprint\": response['system_fingerprint']\n",
    "        }\n",
    "\n",
    "        # Create a table to display the chat history\n",
    "        table = Table(title=f\"Chat History #{counter}\", box=box.ROUNDED)\n",
    "        table.add_column(\"Role\", style=\"cyan\", no_wrap=True)\n",
    "        table.add_column(\"Message\", style=\"magenta\")\n",
    "\n",
    "        for message in local_chat_history:\n",
    "            if message[\"role\"] == \"user\":\n",
    "                table.add_row(\"User\", message[\"content\"])\n",
    "            elif message[\"role\"] == \"assistant\":\n",
    "                table.add_row(\"Assistant\", message[\"content\"])\n",
    "\n",
    "        # Create a panel for statistics\n",
    "        stats_panel = Panel.fit(\n",
    "            Align.center(\n",
    "                \"\\n\".join([f\"{key}: {value}\" for key, value in stats.items()]), \n",
    "                vertical=\"middle\"\n",
    "            ),\n",
    "            title=\"[bold green]Response Stats[/bold green]\",\n",
    "            box=box.ROUNDED\n",
    "        )\n",
    "\n",
    "        # Create a layout to display both table and stats\n",
    "        layout = Table.grid(expand=True)\n",
    "        layout.add_column(justify=\"center\", ratio=3)\n",
    "        layout.add_column(justify=\"center\", ratio=1)\n",
    "        layout.add_row(table, stats_panel)\n",
    "\n",
    "        # Display the layout\n",
    "        console.print(layout)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    local_chat_history = []  # Move chat history initialization outside the loop\n",
    "    counter = 1  # Initialize the message counter\n",
    "    while True:\n",
    "        send_message(local_chat_history, counter)\n",
    "        counter += 1  # Increment the counter after each message\n",
    "        continue_chat = Prompt.ask(\"[bold cyan]Do you want to continue? (yes/no)[/bold cyan]\").lower()\n",
    "        if continue_chat != 'yes':\n",
    "            break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
